{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "86d83a07",
      "cell_type": "code",
      "source": "import numpy as np  \nimport pandas as pd",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "id": "529b490f",
      "cell_type": "code",
      "source": "aisles = pd.read_csv(\"aisles.csv\")\ndepartments = pd.read_csv(\"departments.csv\")\nproducts = pd.read_csv(\"products.csv\")\norders = pd.read_csv(\"orders.csv\")\norder_products = pd.read_csv(\"order_products__train.csv\")\n\nprint(\"aisles:\", aisles.shape)\nprint(\"departments:\", departments.shape)\nprint(\"products:\", products.shape)\nprint(\"orders:\", orders.shape)\nprint(\"order_products__train:\", order_products.shape)\n\n# Quick sanity check\ndisplay(order_products.head())\ndisplay(orders.head())\ndisplay(products.head())\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "aisles: (134, 2)\ndepartments: (21, 2)\nproducts: (49688, 4)\norders: (3421083, 7)\norder_products__train: (1384617, 4)\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "   order_id  product_id  add_to_cart_order  reordered\n0         1       49302                  1          1\n1         1       11109                  2          1\n2         1       10246                  3          0\n3         1       49683                  4          0\n4         1       43633                  5          1",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>order_id</th>\n      <th>product_id</th>\n      <th>add_to_cart_order</th>\n      <th>reordered</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>49302</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>11109</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>10246</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>49683</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>43633</td>\n      <td>5</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "   order_id  user_id eval_set  order_number  order_dow  order_hour_of_day  \\\n0   2539329        1    prior             1          2                  8   \n1   2398795        1    prior             2          3                  7   \n2    473747        1    prior             3          3                 12   \n3   2254736        1    prior             4          4                  7   \n4    431534        1    prior             5          4                 15   \n\n   days_since_prior_order  \n0                     NaN  \n1                    15.0  \n2                    21.0  \n3                    29.0  \n4                    28.0  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>order_id</th>\n      <th>user_id</th>\n      <th>eval_set</th>\n      <th>order_number</th>\n      <th>order_dow</th>\n      <th>order_hour_of_day</th>\n      <th>days_since_prior_order</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2539329</td>\n      <td>1</td>\n      <td>prior</td>\n      <td>1</td>\n      <td>2</td>\n      <td>8</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2398795</td>\n      <td>1</td>\n      <td>prior</td>\n      <td>2</td>\n      <td>3</td>\n      <td>7</td>\n      <td>15.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>473747</td>\n      <td>1</td>\n      <td>prior</td>\n      <td>3</td>\n      <td>3</td>\n      <td>12</td>\n      <td>21.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2254736</td>\n      <td>1</td>\n      <td>prior</td>\n      <td>4</td>\n      <td>4</td>\n      <td>7</td>\n      <td>29.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>431534</td>\n      <td>1</td>\n      <td>prior</td>\n      <td>5</td>\n      <td>4</td>\n      <td>15</td>\n      <td>28.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "   product_id                                       product_name  aisle_id  \\\n0           1                         Chocolate Sandwich Cookies        61   \n1           2                                   All-Seasons Salt       104   \n2           3               Robust Golden Unsweetened Oolong Tea        94   \n3           4  Smart Ones Classic Favorites Mini Rigatoni Wit...        38   \n4           5                          Green Chile Anytime Sauce         5   \n\n   department_id  \n0             19  \n1             13  \n2              7  \n3              1  \n4             13  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>product_id</th>\n      <th>product_name</th>\n      <th>aisle_id</th>\n      <th>department_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Chocolate Sandwich Cookies</td>\n      <td>61</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>All-Seasons Salt</td>\n      <td>104</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Robust Golden Unsweetened Oolong Tea</td>\n      <td>94</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Smart Ones Classic Favorites Mini Rigatoni Wit...</td>\n      <td>38</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Green Chile Anytime Sauce</td>\n      <td>5</td>\n      <td>13</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2
    },
    {
      "id": "37895452",
      "cell_type": "code",
      "source": "df_order_product_ordprod = order_products.merge(orders, on=\"order_id\", how=\"left\")\ndf_order_product_ordprod = df_order_product_ordprod.merge( products[[\"product_id\", \"aisle_id\", \"department_id\"]], on=\"product_id\", how=\"left\")\n\ncurrent_df = df_order_product_ordprod.copy()\ncurrent_df.head(5)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 3,
          "output_type": "execute_result",
          "data": {
            "text/plain": "   order_id  product_id  add_to_cart_order  reordered  user_id eval_set  \\\n0         1       49302                  1          1   112108    train   \n1         1       11109                  2          1   112108    train   \n2         1       10246                  3          0   112108    train   \n3         1       49683                  4          0   112108    train   \n4         1       43633                  5          1   112108    train   \n\n   order_number  order_dow  order_hour_of_day  days_since_prior_order  \\\n0             4          4                 10                     9.0   \n1             4          4                 10                     9.0   \n2             4          4                 10                     9.0   \n3             4          4                 10                     9.0   \n4             4          4                 10                     9.0   \n\n   aisle_id  department_id  \n0       120             16  \n1       108             16  \n2        83              4  \n3        83              4  \n4        95             15  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>order_id</th>\n      <th>product_id</th>\n      <th>add_to_cart_order</th>\n      <th>reordered</th>\n      <th>user_id</th>\n      <th>eval_set</th>\n      <th>order_number</th>\n      <th>order_dow</th>\n      <th>order_hour_of_day</th>\n      <th>days_since_prior_order</th>\n      <th>aisle_id</th>\n      <th>department_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>49302</td>\n      <td>1</td>\n      <td>1</td>\n      <td>112108</td>\n      <td>train</td>\n      <td>4</td>\n      <td>4</td>\n      <td>10</td>\n      <td>9.0</td>\n      <td>120</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>11109</td>\n      <td>2</td>\n      <td>1</td>\n      <td>112108</td>\n      <td>train</td>\n      <td>4</td>\n      <td>4</td>\n      <td>10</td>\n      <td>9.0</td>\n      <td>108</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>10246</td>\n      <td>3</td>\n      <td>0</td>\n      <td>112108</td>\n      <td>train</td>\n      <td>4</td>\n      <td>4</td>\n      <td>10</td>\n      <td>9.0</td>\n      <td>83</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>49683</td>\n      <td>4</td>\n      <td>0</td>\n      <td>112108</td>\n      <td>train</td>\n      <td>4</td>\n      <td>4</td>\n      <td>10</td>\n      <td>9.0</td>\n      <td>83</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>43633</td>\n      <td>5</td>\n      <td>1</td>\n      <td>112108</td>\n      <td>train</td>\n      <td>4</td>\n      <td>4</td>\n      <td>10</td>\n      <td>9.0</td>\n      <td>95</td>\n      <td>15</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3
    },
    {
      "id": "ebb0663d-17ab-4c6c-a039-3fa0b26c4d0b",
      "cell_type": "markdown",
      "source": "### Cleaning and Handling data ###",
      "metadata": {}
    },
    {
      "id": "d9d00305",
      "cell_type": "code",
      "source": "current_df[\"days_since_prior_order\"] = current_df[\"days_since_prior_order\"].fillna(0)\n\n# user ft. 1: user reorder ratio\nuser_reorder_ratio = current_df.groupby(\"user_id\")[\"reordered\"].mean().reset_index()\nuser_reorder_ratio.rename(columns={\"reordered\":\"user_reorder_ratio\"}, inplace=True)\n\ncurrent_df = current_df.merge(user_reorder_ratio, on=\"user_id\", how=\"left\")\n\n# user ft. 2: product reorder probability\nproduct_reorder_prob = current_df.groupby(\"product_id\")[\"reordered\"].mean().reset_index()\nproduct_reorder_prob.rename(columns={\"reordered\":\"product_reorder_prob\"}, inplace=True)\n\n\ncurrent_df = current_df.merge(product_reorder_prob, on=\"product_id\", how=\"left\")\n\n# we will add more features for our prediction task\nX = current_df.drop(columns=[\"reordered\",\"eval_set\"])\ny = current_df[\"reordered\"].astype(int)\n\nX = X.astype(float).to_numpy()\ny = y.astype(int).to_numpy()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 15
    },
    {
      "id": "dd677eba",
      "cell_type": "markdown",
      "source": "### Splitting on Train/test and sampling",
      "metadata": {}
    },
    {
      "id": "78c923aa",
      "cell_type": "code",
      "source": "def train_test_split(X,y, test_size = 0.2, random_state = 42):\n    random_gen = np.random.default_rng(seed=random_state)\n    n_samples = X.shape[0]\n    #shuffling the ds without changing the og array\n    index = random_gen.permutation(n_samples)\n    test_sample = int(n_samples * 0.2)\n    test_index = index[:test_sample]\n    train_index = index[test_sample:]\n\n    return X[train_index], X[test_index], y[train_index], y[test_index]\n\nn_sample = 40000\n\nif X.shape[0] > n_sample:\n    random_gen = np.random.default_rng(seed=42)\n    sample_index = random_gen.choice(X.shape[0], size=n_sample, replace=False)\n    X_small = X[sample_index]\n    y_small = y[sample_index]\nelse:\n    X_small, y_small = X,y\n\nprint(\"Currently using the subset with the size: \", X_small.shape[0])\n\nX_train, X_test, y_train, y_test = train_test_split(X_small, y_small, test_size=0.2, random_state=42)\nprint(\"Train size: \", X_train.shape[0])\nprint(\"Test size: \", X_test.shape[0])\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Currently using the subset with the size:  40000\nTrain size:  32000\nTest size:  8000\n"
        }
      ],
      "execution_count": 16
    },
    {
      "id": "0113e631",
      "cell_type": "markdown",
      "source": "### Feature scaling : We will do the scaling as its imp. that we will not be dependent on one of the feature.\n",
      "metadata": {}
    },
    {
      "id": "f74df30e",
      "cell_type": "code",
      "source": "def min_max_normalization(train, test):\n    min_vals = train.min(axis=0)\n    max_vals = train.max(axis=0)\n    denom = np.where(max_vals - min_vals == 0, 1, max_vals - min_vals)\n\n    train_scaled = (train - min_vals) / denom\n    test_scaled = (test - min_vals) / denom\n\n    return train_scaled, test_scaled, min_vals, max_vals\n\nX_train_scaled, X_test_scaled, min_vals, max_vals = min_max_normalization(X_train, X_test)\n\nprint(\"Scaled feature example (first row):\")\nprint(X_train_scaled[0])",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Scaled feature example (first row):\n[0.89389991 0.79050763 0.05128205 0.29401466 0.0625     1.\n 1.         0.06666667 0.91729323 0.15       0.75       0.68143375]\n"
        }
      ],
      "execution_count": 17
    },
    {
      "id": "81e792f2",
      "cell_type": "code",
      "source": "class KNNClassifier:\n\n    def __init__(self, k):\n        self.k = k\n        self.X_train = None\n        self.y_train = None\n\n    # for storing the training data\n    def fit(self, X, y):\n        self.X_train = np.array(X)\n        self.y_train = np.array(y)\n    \n    def euclid_dist(self, x1,x2):\n        return np.linalg.norm(x1-x2)\n    \n    def predict_one(self,x):\n        # predicting the label for a single eg. x\n\n        distance = np.linalg.norm(self.X_train - x, axis=1)\n\n        knn_index = np.argsort(distance)[:self.k]\n        knn_labels = self.y_train[knn_index]\n\n        #Voting for the majority 0 or 1 \n        one_count = np.sum(knn_labels)\n        zeroes_count = len(knn_labels) - one_count\n\n        return 1 if one_count >= zeroes_count else 0\n    \n    def predict(self, X):\n        X = np.array(X)\n        predictn = [self.predict_one(i) for i in X]\n        return np.array(predictn, dtype=int)\n    \n    def predict_proba(self, X): #for roc_auc\n        X = np.array(X)\n        probabilities = []\n        for x in X:\n            distances = np.linalg.norm(self.X_train - x, axis=1)\n            knn_indices = np.argsort(distances)[:self.k]\n            knn_labels = self.y_train[knn_indices]\n            # Probability = proportion of positive neighbors\n            prob = np.mean(knn_labels)\n            probabilities.append(prob)\n        return np.array(probabilities)\n\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 18
    },
    {
      "id": "e9a5d67f",
      "cell_type": "markdown",
      "source": "### Accuracy of our model",
      "metadata": {}
    },
    {
      "id": "5881d76b",
      "cell_type": "code",
      "source": "def precision_score(y_true, y_pred):\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n    \n    tp = np.sum((y_true == 1) & (y_pred == 1))\n    fp = np.sum((y_true == 0) & (y_pred == 1))\n    \n    if tp + fp == 0:\n        return 0\n    return (tp / (tp + fp))\n\ndef recall_score(y_true, y_pred):\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n    tp = np.sum((y_true == 1) & (y_pred == 1))\n    fn = np.sum((y_true == 1) & (y_pred == 0))\n    if tp + fn == 0:\n        return 0.0\n    return tp / (tp + fn)\n\ndef f1_score(y_true, y_pred):\n    prec = precision_score(y_true, y_pred)\n    rec = recall_score(y_true, y_pred)\n    if prec + rec == 0:\n        return 0.0\n    return 2 * (prec * rec) / (prec + rec)\n\ndef roc_auc_score(y_true, y_scores):\n    sorted_indices = np.argsort(y_scores)[::-1]\n    y_true_sorted = y_true[sorted_indices]\n    \n    # Count positives and negatives\n    n_pos = np.sum(y_true == 1)\n    n_neg = np.sum(y_true == 0)\n    \n    if n_pos == 0 or n_neg == 0:\n        return 0.0\n    \n    tp = 0\n    fp = 0\n    auc = 0\n    prev_tp = 0\n    prev_fp = 0\n    \n    for i in range(len(y_true_sorted)):\n        if y_true_sorted[i] == 1:\n            tp += 1\n        else:\n            fp += 1\n            auc += tp \n \n        if i < len(y_true_sorted) - 1 and y_scores[sorted_indices[i]] != y_scores[sorted_indices[i+1]]:\n            prev_tp = tp\n            prev_fp = fp\n    \n    return auc / (n_pos * n_neg)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 19
    },
    {
      "id": "526f72e8",
      "cell_type": "code",
      "source": "def accuracy_score(y_true, y_pred):\n    # acc = correct/total\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n\n    return np.mean(y_true == y_pred)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 20
    },
    {
      "id": "18a43f65-085e-498d-a0ba-32c3729c7bc2",
      "cell_type": "markdown",
      "source": "### Training and Predicting the Train and Test Dataset respectively, then after evaluating it  ###",
      "metadata": {}
    },
    {
      "id": "d31a5e35",
      "cell_type": "code",
      "source": "knn = KNNClassifier(9)\nknn.fit(X_train_scaled, y_train)\n\ny_pred = knn.predict(X_test_scaled)\ny_proba = knn.predict_proba(X_test_scaled)\n\n\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred)\nrec = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\nauc = roc_auc_score(y_test, y_proba)\n\nprint(f\"The accuracy on the test subset by using our KNN model is: {acc:.4f}\")\nprint(\"=\" * 50)\nprint(f\"Accuracy:  {acc:.4f}\")\nprint(f\"Precision: {prec:.4f}\")\nprint(f\"Recall:    {rec:.4f}\")\nprint(f\"F1 Score:  {f1:.4f}\")\nprint(f\"ROC-AUC:   {auc:.4f}\")\nprint(\"=\" * 50)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "The accuracy on the test subset by using our KNN model is: 0.7508\n==================================================\nAccuracy:  0.7508\nPrecision: 0.7642\nRecall:    0.8448\nF1 Score:  0.8025\nROC-AUC:   0.8121\n==================================================\n"
        }
      ],
      "execution_count": 44
    },
    {
      "id": "8e5dd17f",
      "cell_type": "code",
      "source": "baseline_acc = np.mean(y_test == 1)\nprint(f\"Baseline 'always 1' accuracy: {baseline_acc:.4f}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Baseline 'always 1' accuracy: 0.5994\n"
        }
      ],
      "execution_count": 42
    },
    {
      "id": "0a0bc7e4-b225-4a2c-b4fd-482b5de0015a",
      "cell_type": "markdown",
      "source": "### Cross Validation for best possible k value ###",
      "metadata": {}
    },
    {
      "id": "73d2175a-3168-44be-b464-da24b354c760",
      "cell_type": "code",
      "source": "from sklearn.model_selection import StratifiedKFold\n\n# This is just for finding the best possible k value and also performing stratified k fold\n# croos validation so we can test it on different training and testing dataset. This will return our mean accuracy, f1 score\n# and the ROC area under curve value to see how good the model is.\ndef crossValidation(k, X_train, y_train, n_splits=5):\n    \n    kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n\n    acc_scores = []\n    f1_scores = []\n    auc_scores = []\n\n    for train_idx, val_idx in kfold.split(X_train, y_train):\n        \n        X_tr, X_val = X_train[train_idx], X_train[val_idx]\n        \n        y_tr, y_val = y_train[train_idx], y_train[val_idx]\n\n        knn = KNNClassifier(k=k)\n        \n        knn.fit(X_tr, y_tr)\n        \n        y_val_pred = knn.predict(X_val)\n\n        y_val_scores = y_val_pred.astype(float)\n\n        acc = accuracy_score(y_val, y_val_pred)\n        f1  = f1_score(y_val, y_val_pred)\n\n        \n        acc_scores.append(acc)\n        f1_scores.append(f1)\n        \n        try:\n            auc = roc_auc_score(y_val, y_val_scores)\n        except ValueError:\n            auc = 0.0\n\n        auc_scores.append(auc)\n\n    return np.mean(acc_scores), np.mean(f1_scores), np.mean(auc_scores)\n\n\n# This is some of the k values our team has considered (the list is short because of computation cost, it increases with k value increase)\nk_values = [1, 3, 5, 7, 9, 11, 13, 15, 21, 31]\n\nresults = []\n\nprint(\"For the best k we will take the mean of that best k's evaluation metrics (for each) through k fold \\n\")\nfor k in k_values:\n    mean_acc, mean_f1, mean_auc = crossValidation(k, X_train_scaled, y_train)\n    results.append((k, mean_acc, mean_f1, mean_auc))\n    print(f\"best k = {k:2d} | \"f\"mean Accuracy = {mean_acc:.4f} | \"f\"mean F1 = {mean_f1:.4f} | \"f\"mean ROC-AUC = {mean_auc:.4f}\")\n\n\n# we will take the best evaluation metrics based on our 5 fold cross validation for each of our k values\n# which is then computed by taking mean of it.\nbest_k, best_acc, best_f1, best_auc = max(results, key=lambda x: x[3])\n\nprint(\"\\n###############################################\")\nprint(f\"Best k value based on cross validation: k = {best_k}\")\nprint(f\"Mean Accuracy:  {best_acc:.4f}\")\nprint(f\"Mean F1:        {best_f1:.4f}\")\nprint(f\"Mean ROC-AUC:   {best_auc:.4f}\")\nprint(\"#################################################\\n\")\n\n\n# Now that we got the best k value, we will train our model with this k value on our train set\n# and then predict for our test dataset.\nbest_knn = KNNClassifier(k=best_k)\nbest_knn.fit(X_train_scaled, y_train)\n\ny_test_pred = best_knn.predict(X_test_scaled)\n\ny_test_scores = y_test_pred.astype(float)\ny_test_proba = best_knn.predict_proba(X_test_scaled)\n\n\ntest_acc  = accuracy_score(y_test, y_test_pred)\ntest_prec = precision_score(y_test, y_test_pred)\ntest_rec  = recall_score(y_test, y_test_pred)\ntest_f1   = f1_score(y_test, y_test_pred)\n\ntry:\n    test_auc = roc_auc_score(y_test, y_test_scores)\nexcept ValueError:\n    test_auc = 0.0\n\ntest_auc_proba = roc_auc_score(y_test, y_test_proba)\n\nprint(\"Evaluation of our model with best possible k value\")\nprint(\"---------------------------------------------------------\")\nprint(f\"Best k value: {best_k}\")\nprint(f\"Accuracy:               {test_acc:.4f}\")\nprint(f\"Precision:              {test_prec:.4f}\")\nprint(f\"Recall:                 {test_rec:.4f}\")\nprint(f\"F1 Score:               {test_f1:.4f}\")\nprint(f\"ROC-AUC:                {test_auc:.4f}\")\nprint(f\"ROC-AUC (probability scores):   {test_auc_proba:.4f}\")\nprint(\"---------------------------------------------------------\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Tuning k for scratch KNN using cross-validation (best ROC-AUC)...\n\nk =  1 | CV Accuracy = 0.6849 | CV F1 = 0.7386 | CV ROC-AUC = 0.6701\nk =  3 | CV Accuracy = 0.7198 | CV F1 = 0.7727 | CV ROC-AUC = 0.7011\nk =  5 | CV Accuracy = 0.7368 | CV F1 = 0.7883 | CV ROC-AUC = 0.7164\nk =  7 | CV Accuracy = 0.7469 | CV F1 = 0.7976 | CV ROC-AUC = 0.7256\nk =  9 | CV Accuracy = 0.7498 | CV F1 = 0.8005 | CV ROC-AUC = 0.7279\nk = 11 | CV Accuracy = 0.7543 | CV F1 = 0.8048 | CV ROC-AUC = 0.7317\nk = 13 | CV Accuracy = 0.7564 | CV F1 = 0.8070 | CV ROC-AUC = 0.7332\nk = 15 | CV Accuracy = 0.7571 | CV F1 = 0.8077 | CV ROC-AUC = 0.7336\nk = 21 | CV Accuracy = 0.7602 | CV F1 = 0.8110 | CV ROC-AUC = 0.7358\nk = 31 | CV Accuracy = 0.7639 | CV F1 = 0.8147 | CV ROC-AUC = 0.7386\n\n==========================================\nBest k based on mean CV ROC-AUC: k = 31\nMean CV Accuracy:  0.7639\nMean CV F1:        0.8147\nMean CV ROC-AUC:   0.7386\n==========================================\n\nFinal evaluation of scratch KNN with best_k on TEST set\n---------------------------------------------------------\nBest k (by CV ROC-AUC): 31\nAccuracy:               0.7640\nPrecision:              0.7704\nRecall:                 0.8636\nF1 Score:               0.8144\nROC-AUC:                0.7393\n---------------------------------------------------------\n"
        }
      ],
      "execution_count": 26
    },
    {
      "id": "88033d4c-913f-467b-b0f3-def4f7fffa6b",
      "cell_type": "code",
      "source": "# The below output cell is included above, you can see this in the above cell if you rerun the whole code, the below is the main ROC-AUC \n# probability scores for our model",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "ROC-AUC (probability scores):   0.8354\n"
        }
      ],
      "execution_count": 45
    },
    {
      "id": "634661ee-ec72-40e8-878d-c0b53a2786f7",
      "cell_type": "markdown",
      "source": "### Other Predictive Models for Comparison ###",
      "metadata": {}
    },
    {
      "id": "456e9bc6-97fe-463e-9ba6-be57f132a33a",
      "cell_type": "code",
      "source": "from xgboost import XGBClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\n\n# this is for training the models and printing their evaluation metrics\ndef evaluate_model(name, model, X_train, X_test, y_train, y_test):\n    \n    print(f\"Training model: {name}\")    \n    model.fit(X_train, y_train)\n\n    y_pred = model.predict(X_test)\n    y_proba = model.predict_proba(X_test)[:, 1]\n    \n    acc  = accuracy_score(y_test, y_pred)\n    prec = precision_score(y_test, y_pred)\n    rec  = recall_score(y_test, y_pred)\n    f1   = f1_score(y_test, y_pred)\n    \n    auc = roc_auc_score(y_test, y_proba)\n    \n    print(f\"Accuracy:  {acc:.4f}\")\n    print(f\"Precision: {prec:.4f}\")\n    print(f\"Recall:    {rec:.4f}\")\n    print(f\"F1 Score:  {f1:.4f}\")\n    print(f\"ROC-AUC:   {auc:.4f}\")\n    \n    print(\"=\" * 60)\n    print()\n\nlr = LogisticRegression(\n    max_iter=1000,\n    n_jobs=-1,\n    class_weight=\"balanced\"\n)\n\nrf = RandomForestClassifier(\n    n_estimators=600,\n    random_state=42,\n    n_jobs=-1\n)\n\nxgb = XGBClassifier(\n    n_estimators=600,\n    learning_rate=0.05,\n    max_depth=6,\n    subsample=0.8,\n    colsample_bytree=0.6,\n    random_state=42,\n    n_jobs=-1,\n)\n\nmodels = {\n    \"Logistic Regression\": lr,\n    \"Random Forest\": rf,\n    \"XGBoost\": xgb\n}\n\n\nfor name, model in models.items():\n    evaluate_model(name, model, X_train_scaled, X_test_scaled, y_train, y_test)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "============================================================\nTraining model: Logistic Regression\n============================================================\nAccuracy:  0.7734\nPrecision: 0.8342\nRecall:    0.7762\nF1 Score:  0.8041\nROC-AUC:   0.8607\n============================================================\n\n============================================================\nTraining model: Random Forest\n============================================================\nAccuracy:  0.7800\nPrecision: 0.8019\nRecall:    0.8407\nF1 Score:  0.8208\nROC-AUC:   0.8594\n============================================================\n\n============================================================\nTraining model: XGBoost\n============================================================\nAccuracy:  0.7825\nPrecision: 0.8052\nRecall:    0.8405\nF1 Score:  0.8224\nROC-AUC:   0.8658\n============================================================\n\n"
        }
      ],
      "execution_count": 49
    },
    {
      "id": "1601c6a7-1e55-46f6-b205-3fc299f9cba9",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}